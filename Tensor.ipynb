{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGc5EwsF6m2XPtSsYn4NiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leodavidfan/AI_Books/blob/main/Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fgl5XDgd7QxN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# PyTorch scalar operations\n",
        "scalar_pt = torch.tensor (5.0)\n",
        "log_scalar = torch.log( scalar_pt )\n",
        "exp_scalar = torch.exp( scalar_pt )\n",
        "\n",
        "# TensorFlow scalar operations\n",
        "scalar_tf = tf. constant (5.0)\n",
        "log_scalar = tf. math .log( scalar_tf )\n",
        "exp_scalar = tf. math .exp( scalar_tf )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Vector Operations). Implementation of basic vector operations:\n",
        "\n",
        "# Create vectors\n",
        "u = torch . tensor ([1. , 2., 3.])\n",
        "v = torch . tensor ([4. , 5., 6.])\n",
        "\n",
        "# Basic operations\n",
        "sum_vec = u + v\n",
        "scaled = 2 * u\n",
        "dot_product = torch . dot(u, v)\n",
        "norm = torch . norm (u)\n",
        "\n",
        "# Vector transformations\n",
        "normalized = u / norm\n",
        "projection = ( torch .dot(u, v) / torch . dot(u, u)) * u"
      ],
      "metadata": {
        "id": "L5Fd0bhN71bc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Matrix Operations). Implementation of matrix operations:\n",
        "\n",
        "# Create matrices\n",
        "A = torch . tensor ([[1. , 2.] , [3. , 4.]])\n",
        "B = torch . tensor ([[5. , 6.] , [7. , 8.]])\n",
        "\n",
        "# Basic operations\n",
        "sum_matrix = A + B\n",
        "product = torch . matmul (A, B)\n",
        "transpose = A.t()\n",
        "determinant = torch . det(A)\n",
        "inverse = torch . inverse (A)\n",
        "trace = torch . trace (A)\n",
        "\n",
        "# Eigendecomposition\n",
        "eigenvalues , eigenvectors = torch . linalg .eig(A)"
      ],
      "metadata": {
        "id": "COFvG4ET8G_7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a rank -4 tensor\n",
        "T = torch.randn (2, 3, 3, 2)\n",
        "\n",
        "# Contract over middle indices\n",
        "C = torch.einsum ('ijjk ->ik', T)"
      ],
      "metadata": {
        "id": "_kZqzlK-8Pi4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "T = torch . randn (4, 3)\n",
        "\n",
        "# Compute SVD\n",
        "U, S, V = torch.linalg.svd (T)\n",
        "\n",
        "# Reconstruct original tensor\n",
        "T_reconstructed = U @ torch.diag(S) @ V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "DvarYXMb8dDt",
        "outputId": "cab79884-f9a7-49ac-c373-d46a8bb59323"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x4 and 3x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8f00535bf68f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Reconstruct original tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mT_reconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x4 and 3x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory - efficient tensor creation\n",
        "efficient = torch . randn (1000 , 1000 ,dtype = torch . float32 ) # 4MB\n",
        "\n",
        " # Memory - inefficient tensor\n",
        "inefficient = torch . randn (1000 , 1000 ,dtype = torch . float64 ) # 8MB\n",
        "\n",
        " # Use in - place operations\n",
        "efficient . add_ (1) # In - place addition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjY-3mE19dVm",
        "outputId": "febe63c9-ca31-47d9-b2d1-8dbeda711d2d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4966,  0.5558,  0.5378,  ...,  1.0561, -0.2736,  1.2252],\n",
              "        [-0.0530, -0.9015,  1.1406,  ...,  0.9508,  1.3669,  1.4165],\n",
              "        [ 0.6605,  2.2796,  2.2498,  ..., -0.6056,  0.6745, -0.4631],\n",
              "        ...,\n",
              "        [ 0.7781,  0.1003,  1.8459,  ...,  1.0867,  0.8836,  1.3513],\n",
              "        [-0.6450,  0.9343,  0.6779,  ...,  0.2078,  0.3838, -0.1355],\n",
              "        [ 1.0522,  1.8059,  2.0398,  ...,  0.6334,  0.3335,  2.3760]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Comparison\n",
        "\n",
        "import time\n",
        "def slow_operation ( tensor ):\n",
        "  result = torch . zeros_like ( tensor )\n",
        "  for i in range ( tensor . shape [0]) :\n",
        "    for j in range ( tensor . shape [1]) :\n",
        "      result [i,j] = torch .sin ( tensor [i,j])\n",
        "  return result\n",
        "\n",
        "def fast_operation ( tensor ):\n",
        "  return torch .sin ( tensor )\n",
        "\n",
        "# Compare performance\n",
        "x = torch . randn (1000 , 1000)\n",
        "\n",
        "start = time . time ()\n",
        "slow_result = slow_operation (x)\n",
        "print (f\" Loop time : { time . time () - start :.2f}s\")\n",
        "\n",
        "start = time . time ()\n",
        "fast_result = fast_operation (x)\n",
        "print (f\" Vectorized time : { time . time () - start :.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z32SRxvU9v4r",
        "outputId": "3db1f4ab-a17d-4082-b8e5-ec1969b835b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loop time : 17.94s\n",
            " Vectorized time : 0.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Efficient Implementation\n",
        "\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "def analyze_matrix (A):\n",
        "  \"\"\"\n",
        "  Comprehensive analysis of a matrix using eigenvalue\n",
        "  decomposition .\n",
        "  Parameters :\n",
        "  -----------\n",
        "  A : ndarray\n",
        "  Square matrix to analyze\n",
        "\n",
        "  Returns :\n",
        "  --------\n",
        "  dict\n",
        "  Dictionary containing eigenvalues , eigenvectors , condition\n",
        "  number ,\n",
        "  and stability analysis\n",
        "  \"\"\"\n",
        "    # Compute eigendecomposition\n",
        "  eigenvals , eigenvecs = linalg .eig(A)\n",
        "\n",
        "  # Compute condition number\n",
        "  cond_num = np. linalg . cond (A)\n",
        "\n",
        "  # Analyze stability\n",
        "  is_stable = np.all(np. real ( eigenvals ) < 0)\n",
        "\n",
        "  # Verify diagonalization\n",
        "  D = np. diag ( eigenvals )\n",
        "  P = eigenvecs\n",
        "  P_inv = np. linalg .inv(P)\n",
        "  reconstruction_error = np. linalg . norm (A - P @ D @ P_inv )\n",
        "\n",
        "  return {\n",
        "  'eigenvalues': eigenvals ,\n",
        "  'eigenvectors': eigenvecs ,\n",
        "  'condition_number': cond_num ,\n",
        "  'is_stable': is_stable ,\n",
        "  'reconstruction_error': reconstruction_error\n",
        " }"
      ],
      "metadata": {
        "id": "Oav1lsIt-xMp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "class MovieData :\n",
        "  def __init__ (self , ratings_file , movies_file ):\n",
        "    \"\"\" Initialize MovieData with rating and movie information .\n",
        "    \"\"\"\n",
        "    self . ratings = pd. read_csv ( ratings_file )\n",
        "    self . movies = pd. read_csv ( movies_file )\n",
        "    self . _prepare_matrices ()\n",
        "\n",
        "  def _prepare_matrices ( self ):\n",
        "    \"\"\"\n",
        "    Convert ratings into a 2D NumPy array ( users x movies ).\n",
        "    Missing values remain NaN.\n",
        "    \"\"\"\n",
        "    self . ratings_matrix = self . ratings . pivot (\n",
        "    index ='user_id',\n",
        "    columns ='movie_id',\n",
        "    values ='rating'\n",
        "    ). values\n",
        "\n",
        "  # Compute the mean rating per user ( ignoring NaN)\n",
        "    self. user_means = np. nanmean ( self . ratings_matrix , axis =1, keepdims = True )\n",
        "\n",
        "  # Create a centered rating matrix (user - means subtracted )\n",
        "    self. centered_ratings = self . ratings_matrix - self .user_means"
      ],
      "metadata": {
        "id": "_bgeLfgzAJx9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD-based recommender systems is the Alternating Least Squares\n",
        "# (ALS) method.\n",
        "\n",
        "class SVDRecommender :\n",
        "  def __init__ (self , n_factors =20 , regularization =0.1) :\n",
        "    \"\"\"\n",
        "    n_factors : Number of latent factors (k in R ~ P x Q^T).\n",
        "    regularization : L2 regularization strength ( lambda ).\n",
        "    \"\"\"\n",
        "    self . n_factors = n_factors\n",
        "    self .reg = regularization\n",
        "\n",
        "  def fit(self , ratings_matrix , n_epochs =10) :\n",
        "    \"\"\"\n",
        "    Train the model using Alternating Least Squares ( ALS).\n",
        "    ratings_matrix : 2D NumPy array of shape ( n_users , n_items ),\n",
        "    with NaN for missing ratings .\n",
        "    n_epochs : Number of ALS iterations .\n",
        "    \"\"\"\n",
        "    self . ratings = ratings_matrix\n",
        "    self . n_users , self . n_items = ratings_matrix . shape\n",
        "\n",
        "    # Initialize user_factors and item_factors randomly\n",
        "    self . user_factors = np. random . normal (0, 0.1 , ( self . n_users , self . n_factors ))\n",
        "    self . item_factors = np. random . normal (0, 0.1 , ( self . n_items , self . n_factors ))\n",
        "\n",
        "    for epoch in range ( n_epochs ):\n",
        "    # 1) Update all user factors\n",
        "      for u in range ( self . n_users ):\n",
        "        rated_items = ~np. isnan ( self . ratings [u])\n",
        "      if not np.any (rated_items ):\n",
        "        continue\n",
        "\n",
        "    # Solve (Q^T Q + lambda *I) p_u = Q^T r_u\n",
        "    A = ( self . item_factors [ rated_items ].T @ self . item_factors [ rated_items ] + self .reg * np.eye( self . n_factors ))\n",
        "    b = self . item_factors [ rated_items ].T @ self . ratings [u, rated_items ]\n",
        "    self . user_factors [u] = np. linalg . solve (A, b)\n",
        "\n",
        "    # 2) Update all item factors\n",
        "    for i in range ( self . n_items ):\n",
        "      rated_users = ~np. isnan ( self . ratings [:, i])\n",
        "      if not np.any ( rated_users ):\n",
        "        continue\n",
        "\n",
        "      A = ( self . user_factors [ rated_users ].T @ self . user_factors [ rated_users ] + self .reg * np.eye( self . n_factors ))\n",
        "      b = self . user_factors [ rated_users ].T @ self . ratings [rated_users , i]\n",
        "      self . item_factors [i] = np. linalg . solve (A, b)\n",
        "\n",
        "      # Print progress every 2 epochs (as an example )\n",
        "      if ( epoch +1) % 2 == 0:\n",
        "        rmse_val = self . compute_error ()\n",
        "        print (f\" Epoch { epoch +1}/{ n_epochs }, RMSE = { rmse_val:.4 f}\")\n",
        "\n",
        "  def compute_error ( self ):\n",
        "    \"\"\"\n",
        "    Compute RMSE on known (non -NaN) ratings .\n",
        "    \"\"\"\n",
        "    predicted_matrix = self . user_factors @ self . item_factors .T\n",
        "    mask = ~np. isnan ( self . ratings )\n",
        "    mse = np. mean (( self . ratings [ mask ] - predicted_matrix [ mask ])** 2)\n",
        "    return np. sqrt (mse )\n",
        "\n",
        "  def predict_rating (self , user_id , item_id ):\n",
        "    \"\"\"\n",
        "    Predict a single rating using user and item factor dot product .\n",
        "    \"\"\"\n",
        "    return np.dot ( self . user_factors [ user_id ], self . item_factors [item_id ])\n",
        "\n",
        "  def recommend_items (self , user_id , n_recommendations =5):\n",
        "    \"\"\"\n",
        "      Recommend top N items for a given user ,\n",
        "    ignoring items already rated by that user .\n",
        "    \"\"\"\n",
        "    user_vector = self . user_factors [ user_id ]\n",
        "    predictions = user_vector @ self . item_factors .T\n",
        "    already_rated = ~np. isnan ( self . ratings [ user_id ])\n",
        "    predictions [ already_rated ] = -np.inf # to exclude rated items\n",
        "    top_items = np. argsort ( predictions ) [:: -1][: n_recommendations]\n",
        "    return top_items"
      ],
      "metadata": {
        "id": "ElUBcr0VA7oX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute both metrics, given a trained model and a test ratings matrix\n",
        "\n",
        "def evaluate_model (model , test_ratings ):\n",
        "  \"\"\"\n",
        "  Compute RMSE and MAE on a test set with known (non -NaN) ratings .\n",
        "  \"\"\"\n",
        "  predicted = model . user_factors @ model . item_factors .T\n",
        "  mask = ~np. isnan ( test_ratings )\n",
        "\n",
        "  errors = test_ratings [ mask ] - predicted [ mask ]\n",
        "  rmse = np. sqrt (np. mean ( errors **2) )\n",
        "  mae = np. mean (np.abs( errors ))\n",
        "\n",
        "  return rmse , mae"
      ],
      "metadata": {
        "id": "W6lkNCQpEAIm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent (SGD) version that updates biases and factor vectors together\n",
        "\n",
        "class BiasedSVD :\n",
        "  def __init__ (self , n_factors =20 , reg =0.1 , lr =0.005) :\n",
        "    self . n_factors = n_factors\n",
        "    self .reg = reg\n",
        "    self .lr = lr\n",
        "\n",
        "  def fit(self , ratings_matrix , n_epochs =10) :\n",
        "    self . ratings = ratings_matrix\n",
        "    self . n_users , self . n_items = ratings_matrix . shape\n",
        "\n",
        "    self . global_mean = np. nanmean ( self . ratings )\n",
        "    self . user_bias = np. zeros ( self . n_users )\n",
        "    self . item_bias = np. zeros ( self . n_items )\n",
        "    self . user_factors = np. random . normal (0, 0.1 , ( self . n_users , self . n_factors ))\n",
        "    self . item_factors = np. random . normal (0, 0.1 , ( self . n_items , self . n_factors ))\n",
        "\n",
        "    for epoch in range ( n_epochs ):\n",
        "      user_ids , item_ids = np. where (~ np. isnan ( self . ratings ))\n",
        "      indices = np. random . permutation (len( user_ids ))\n",
        "\n",
        "    for idx in indices :\n",
        "      u = user_ids [idx]\n",
        "\n",
        "      i = item_ids [idx]\n",
        "      rating = self . ratings [u, i]\n",
        "\n",
        "      # Current prediction\n",
        "      pred = ( self . global_mean +\n",
        "      self . user_bias [u] +\n",
        "      self . item_bias [i] +\n",
        "      np. dot ( self . user_factors [u], self .item_factors [i]))\n",
        "\n",
        "      # Error\n",
        "      e_ui = rating - pred\n",
        "\n",
        "      # Update bias terms\n",
        "      self . user_bias [u] += self .lr * ( e_ui - self .reg * self . user_bias [u])\n",
        "      self . item_bias [i] += self .lr * ( e_ui - self .reg * self . item_bias [i])\n",
        "\n",
        "      # Update latent factors\n",
        "      u_factors_old = self . user_factors [u]. copy ()\n",
        "      self . user_factors [u] += self .lr * (e_ui * self . item_factors [i] - self .reg * self .user_factors [u])\n",
        "      self . item_factors [i] += self .lr * ( e_ui * u_factors_old - self .reg * self .item_factors [i] )\n",
        "\n",
        "      # Monitor training progress ( RMSE )\n",
        "      rmse_val = self . _compute_rmse ()\n",
        "      print (f\" Epoch { epoch +1}/{ n_epochs }, RMSE = { rmse_val :.4f}\")\n",
        "\n",
        "  def _compute_rmse ( self ):\n",
        "    predictions = self . _full_prediction_matrix ()\n",
        "    mask = ~np. isnan ( self . ratings )\n",
        "    mse = np. mean (( self . ratings [ mask ] - predictions [ mask ]) ** 2)\n",
        "    return np. sqrt (mse )\n",
        "\n",
        "  def _full_prediction_matrix ( self ):\n",
        "    bias_term = ( self . global_mean +\n",
        "    self . user_bias [:, None ] +\n",
        "    self . item_bias [None , :])\n",
        "    factor_term = self . user_factors @ self . item_factors .T\n",
        "    return bias_term + factor_term\n",
        "\n",
        "  def predict (self , user_id , item_id ):\n",
        "   return self . _full_prediction_matrix ()[ user_id , item_id ]\n",
        "\n",
        "  def recommend_items (self , user_id , n_recommendations =5):\n",
        "    preds = self . _full_prediction_matrix ()[ user_id ]\n",
        "    rated_mask = ~np. isnan ( self . ratings [ user_id ])\n",
        "    preds [ rated_mask ] = -np.inf\n",
        "    return np. argsort ( preds ) [:: -1][: n_recommendations ]"
      ],
      "metadata": {
        "id": "8ZyQwi-LEGr1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \" __main__ \":\n",
        "  # Choose our SVD model\n",
        "  model = BiasedSVD ( n_factors =20 , reg =0.1 , lr =0.005)\n",
        "  # Fit on training set\n",
        "  model .fit( train_ratings , n_epochs =10)\n",
        "  # Evaluate on test set\n",
        "  rmse , mae = evaluate_model (model , test_ratings )\n",
        "  print (f\" Final RMSE on test = { rmse :.4f}, MAE = { mae :.4f}\")\n",
        "\n",
        "  # Make top -5 recommendations for user 0\n",
        "  user_id = 0\n",
        "  recommendations = model . recommend_items ( user_id , n_recommendations =5)\n",
        "  print (\"Top 5 Recommendations for user 0:\", recommendations )"
      ],
      "metadata": {
        "id": "LgfCvt7mFu3i"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Backpropagation applies the chain rule to compute how changes in parameters influence the final loss.\n",
        "\n",
        "• The loss function measures the discrepancy between predictions and true labels.\n",
        "\n",
        "• The chain rule in calculus is the mathematical linchpin enabling efficient gradient computation.\n",
        "\n",
        "• Gradient descent moves parameters in the opposite direction of the gradient to minimize 𝐿(𝜃).\n",
        "\n",
        "• Choices like activation function, loss function, and learning rate can vastly impact training efficacy and speed."
      ],
      "metadata": {
        "id": "X-Ybe0jxGjxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python snippet demonstrating the forward and backward pass for a single-neuron model with a Sigmoid activation and MSE loss:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Example values\n",
        "x, w, b, y = 2.0, 0.5, 0.1, 1.0 # input, weight, bias, target\n",
        "\n",
        "# Forward pass\n",
        "z = w * x + b # linear combination\n",
        "a = 1 / (1 + np.exp(-z)) # sigmoid activation\n",
        "loss = (y - a)**2 # MSE loss\n",
        "print(\"Forward pass results:\")\n",
        "print(f\"z = {z}, a = {a}, loss = {loss}\")\n",
        "\n",
        "# Backward pass\n",
        "dL_da = 2 * (a - y) # derivative of MSE w.r.t. a\n",
        "da_dz = a * (1 - a) # derivative of sigmoid w.r.t. z\n",
        "dz_dw = x # derivative of z w.r.t. w\n",
        "dz_db = 1 # derivative of z w.r.t. b\n",
        "\n",
        "# Combine derivatives to get the gradient\n",
        "dL_dw = dL_da * da_dz * dz_dw\n",
        "dL_db = dL_da * da_dz * dz_db\n",
        "print(\"\\nBackward pass (gradients):\")\n",
        "print(f\"dL/da = {dL_da}\")\n",
        "print(f\"da/dz = {da_dz}\")\n",
        "print(f\"dz/dw = {dz_dw}\")\n",
        "print(f\"dz/db = {dz_db}\")\n",
        "print(f\"dL/dw = {dL_dw}\")\n",
        "print(f\"dL/db = {dL_db}\")\n",
        "\n",
        "# Update parameters\n",
        "eta = 0.1\n",
        "w_new = w - eta * dL_dw\n",
        "b_new = b - eta * dL_db\n",
        "print(\"\\nUpdated parameters:\")\n",
        "print(f\"w_new = {w_new}\")\n",
        "print(f\"b_new = {b_new}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs90vypWGP7Z",
        "outputId": "45ac23f4-1773-46f1-af27-768afd23b07b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward pass results:\n",
            "z = 1.1, a = 0.7502601055951177, loss = 0.062370014857361766\n",
            "\n",
            "Backward pass (gradients):\n",
            "dL/da = -0.4994797888097646\n",
            "da/dz = 0.18736987954752055\n",
            "dz/dw = 2.0\n",
            "dz/db = 1\n",
            "dL/dw = -0.1871749357314132\n",
            "dL/db = -0.0935874678657066\n",
            "\n",
            "Updated parameters:\n",
            "w_new = 0.5187174935731413\n",
            "b_new = 0.10935874678657066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "\n",
        "• Michael A. Nielsen: Neural Networks and Deep Learning (free online resource).\n",
        "\n",
        "• Ian Goodfellow, Yoshua Bengio, Aaron Courville: Deep Learning (MIT Press).\n",
        "\n",
        "• Andrew Ng’s Coursera course on Machine Learning for foundational gradient-based method insights."
      ],
      "metadata": {
        "id": "7vQtf25MGydq"
      }
    }
  ]
}