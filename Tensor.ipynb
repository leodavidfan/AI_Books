{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGc5EwsF6m2XPtSsYn4NiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leodavidfan/AI_Books/blob/main/Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fgl5XDgd7QxN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# PyTorch scalar operations\n",
        "scalar_pt = torch.tensor (5.0)\n",
        "log_scalar = torch.log( scalar_pt )\n",
        "exp_scalar = torch.exp( scalar_pt )\n",
        "\n",
        "# TensorFlow scalar operations\n",
        "scalar_tf = tf. constant (5.0)\n",
        "log_scalar = tf. math .log( scalar_tf )\n",
        "exp_scalar = tf. math .exp( scalar_tf )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Vector Operations). Implementation of basic vector operations:\n",
        "\n",
        "# Create vectors\n",
        "u = torch . tensor ([1. , 2., 3.])\n",
        "v = torch . tensor ([4. , 5., 6.])\n",
        "\n",
        "# Basic operations\n",
        "sum_vec = u + v\n",
        "scaled = 2 * u\n",
        "dot_product = torch . dot(u, v)\n",
        "norm = torch . norm (u)\n",
        "\n",
        "# Vector transformations\n",
        "normalized = u / norm\n",
        "projection = ( torch .dot(u, v) / torch . dot(u, u)) * u"
      ],
      "metadata": {
        "id": "L5Fd0bhN71bc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Matrix Operations). Implementation of matrix operations:\n",
        "\n",
        "# Create matrices\n",
        "A = torch . tensor ([[1. , 2.] , [3. , 4.]])\n",
        "B = torch . tensor ([[5. , 6.] , [7. , 8.]])\n",
        "\n",
        "# Basic operations\n",
        "sum_matrix = A + B\n",
        "product = torch . matmul (A, B)\n",
        "transpose = A.t()\n",
        "determinant = torch . det(A)\n",
        "inverse = torch . inverse (A)\n",
        "trace = torch . trace (A)\n",
        "\n",
        "# Eigendecomposition\n",
        "eigenvalues , eigenvectors = torch . linalg .eig(A)"
      ],
      "metadata": {
        "id": "COFvG4ET8G_7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a rank -4 tensor\n",
        "T = torch.randn (2, 3, 3, 2)\n",
        "\n",
        "# Contract over middle indices\n",
        "C = torch.einsum ('ijjk ->ik', T)"
      ],
      "metadata": {
        "id": "_kZqzlK-8Pi4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "T = torch . randn (4, 3)\n",
        "\n",
        "# Compute SVD\n",
        "U, S, V = torch.linalg.svd (T)\n",
        "\n",
        "# Reconstruct original tensor\n",
        "T_reconstructed = U @ torch.diag(S) @ V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "DvarYXMb8dDt",
        "outputId": "cab79884-f9a7-49ac-c373-d46a8bb59323"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x4 and 3x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8f00535bf68f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Reconstruct original tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mT_reconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x4 and 3x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory - efficient tensor creation\n",
        "efficient = torch . randn (1000 , 1000 ,dtype = torch . float32 ) # 4MB\n",
        "\n",
        " # Memory - inefficient tensor\n",
        "inefficient = torch . randn (1000 , 1000 ,dtype = torch . float64 ) # 8MB\n",
        "\n",
        " # Use in - place operations\n",
        "efficient . add_ (1) # In - place addition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjY-3mE19dVm",
        "outputId": "febe63c9-ca31-47d9-b2d1-8dbeda711d2d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4966,  0.5558,  0.5378,  ...,  1.0561, -0.2736,  1.2252],\n",
              "        [-0.0530, -0.9015,  1.1406,  ...,  0.9508,  1.3669,  1.4165],\n",
              "        [ 0.6605,  2.2796,  2.2498,  ..., -0.6056,  0.6745, -0.4631],\n",
              "        ...,\n",
              "        [ 0.7781,  0.1003,  1.8459,  ...,  1.0867,  0.8836,  1.3513],\n",
              "        [-0.6450,  0.9343,  0.6779,  ...,  0.2078,  0.3838, -0.1355],\n",
              "        [ 1.0522,  1.8059,  2.0398,  ...,  0.6334,  0.3335,  2.3760]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Comparison\n",
        "\n",
        "import time\n",
        "def slow_operation ( tensor ):\n",
        "  result = torch . zeros_like ( tensor )\n",
        "  for i in range ( tensor . shape [0]) :\n",
        "    for j in range ( tensor . shape [1]) :\n",
        "      result [i,j] = torch .sin ( tensor [i,j])\n",
        "  return result\n",
        "\n",
        "def fast_operation ( tensor ):\n",
        "  return torch .sin ( tensor )\n",
        "\n",
        "# Compare performance\n",
        "x = torch . randn (1000 , 1000)\n",
        "\n",
        "start = time . time ()\n",
        "slow_result = slow_operation (x)\n",
        "print (f\" Loop time : { time . time () - start :.2f}s\")\n",
        "\n",
        "start = time . time ()\n",
        "fast_result = fast_operation (x)\n",
        "print (f\" Vectorized time : { time . time () - start :.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z32SRxvU9v4r",
        "outputId": "3db1f4ab-a17d-4082-b8e5-ec1969b835b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loop time : 17.94s\n",
            " Vectorized time : 0.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Efficient Implementation\n",
        "\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "def analyze_matrix (A):\n",
        "  \"\"\"\n",
        "  Comprehensive analysis of a matrix using eigenvalue\n",
        "  decomposition .\n",
        "  Parameters :\n",
        "  -----------\n",
        "  A : ndarray\n",
        "  Square matrix to analyze\n",
        "\n",
        "  Returns :\n",
        "  --------\n",
        "  dict\n",
        "  Dictionary containing eigenvalues , eigenvectors , condition\n",
        "  number ,\n",
        "  and stability analysis\n",
        "  \"\"\"\n",
        "    # Compute eigendecomposition\n",
        "  eigenvals , eigenvecs = linalg .eig(A)\n",
        "\n",
        "  # Compute condition number\n",
        "  cond_num = np. linalg . cond (A)\n",
        "\n",
        "  # Analyze stability\n",
        "  is_stable = np.all(np. real ( eigenvals ) < 0)\n",
        "\n",
        "  # Verify diagonalization\n",
        "  D = np. diag ( eigenvals )\n",
        "  P = eigenvecs\n",
        "  P_inv = np. linalg .inv(P)\n",
        "  reconstruction_error = np. linalg . norm (A - P @ D @ P_inv )\n",
        "\n",
        "  return {\n",
        "  'eigenvalues': eigenvals ,\n",
        "  'eigenvectors': eigenvecs ,\n",
        "  'condition_number': cond_num ,\n",
        "  'is_stable': is_stable ,\n",
        "  'reconstruction_error': reconstruction_error\n",
        " }"
      ],
      "metadata": {
        "id": "Oav1lsIt-xMp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "class MovieData :\n",
        "  def __init__ (self , ratings_file , movies_file ):\n",
        "    \"\"\" Initialize MovieData with rating and movie information .\n",
        "    \"\"\"\n",
        "    self . ratings = pd. read_csv ( ratings_file )\n",
        "    self . movies = pd. read_csv ( movies_file )\n",
        "    self . _prepare_matrices ()\n",
        "\n",
        "  def _prepare_matrices ( self ):\n",
        "    \"\"\"\n",
        "    Convert ratings into a 2D NumPy array ( users x movies ).\n",
        "    Missing values remain NaN.\n",
        "    \"\"\"\n",
        "    self . ratings_matrix = self . ratings . pivot (\n",
        "    index ='user_id',\n",
        "    columns ='movie_id',\n",
        "    values ='rating'\n",
        "    ). values\n",
        "\n",
        "  # Compute the mean rating per user ( ignoring NaN)\n",
        "    self. user_means = np. nanmean ( self . ratings_matrix , axis =1, keepdims = True )\n",
        "\n",
        "  # Create a centered rating matrix (user - means subtracted )\n",
        "    self. centered_ratings = self . ratings_matrix - self .user_means"
      ],
      "metadata": {
        "id": "_bgeLfgzAJx9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD-based recommender systems is the Alternating Least Squares\n",
        "# (ALS) method.\n",
        "\n",
        "class SVDRecommender :\n",
        "  def __init__ (self , n_factors =20 , regularization =0.1) :\n",
        "    \"\"\"\n",
        "    n_factors : Number of latent factors (k in R ~ P x Q^T).\n",
        "    regularization : L2 regularization strength ( lambda ).\n",
        "    \"\"\"\n",
        "    self . n_factors = n_factors\n",
        "    self .reg = regularization\n",
        "\n",
        "  def fit(self , ratings_matrix , n_epochs =10) :\n",
        "    \"\"\"\n",
        "    Train the model using Alternating Least Squares ( ALS).\n",
        "    ratings_matrix : 2D NumPy array of shape ( n_users , n_items ),\n",
        "    with NaN for missing ratings .\n",
        "    n_epochs : Number of ALS iterations .\n",
        "    \"\"\"\n",
        "    self . ratings = ratings_matrix\n",
        "    self . n_users , self . n_items = ratings_matrix . shape\n",
        "\n",
        "    # Initialize user_factors and item_factors randomly\n",
        "    self . user_factors = np. random . normal (0, 0.1 , ( self . n_users , self . n_factors ))\n",
        "    self . item_factors = np. random . normal (0, 0.1 , ( self . n_items , self . n_factors ))\n",
        "\n",
        "    for epoch in range ( n_epochs ):\n",
        "    # 1) Update all user factors\n",
        "      for u in range ( self . n_users ):\n",
        "        rated_items = ~np. isnan ( self . ratings [u])\n",
        "      if not np.any (rated_items ):\n",
        "        continue\n",
        "\n",
        "    # Solve (Q^T Q + lambda *I) p_u = Q^T r_u\n",
        "    A = ( self . item_factors [ rated_items ].T @ self . item_factors [ rated_items ] + self .reg * np.eye( self . n_factors ))\n",
        "    b = self . item_factors [ rated_items ].T @ self . ratings [u, rated_items ]\n",
        "    self . user_factors [u] = np. linalg . solve (A, b)\n",
        "\n",
        "    # 2) Update all item factors\n",
        "    for i in range ( self . n_items ):\n",
        "      rated_users = ~np. isnan ( self . ratings [:, i])\n",
        "      if not np.any ( rated_users ):\n",
        "        continue\n",
        "\n",
        "      A = ( self . user_factors [ rated_users ].T @ self . user_factors [ rated_users ] + self .reg * np.eye( self . n_factors ))\n",
        "      b = self . user_factors [ rated_users ].T @ self . ratings [rated_users , i]\n",
        "      self . item_factors [i] = np. linalg . solve (A, b)\n",
        "\n",
        "      # Print progress every 2 epochs (as an example )\n",
        "      if ( epoch +1) % 2 == 0:\n",
        "        rmse_val = self . compute_error ()\n",
        "        print (f\" Epoch { epoch +1}/{ n_epochs }, RMSE = { rmse_val:.4 f}\")\n",
        "\n",
        "  def compute_error ( self ):\n",
        "    \"\"\"\n",
        "    Compute RMSE on known (non -NaN) ratings .\n",
        "    \"\"\"\n",
        "    predicted_matrix = self . user_factors @ self . item_factors .T\n",
        "    mask = ~np. isnan ( self . ratings )\n",
        "    mse = np. mean (( self . ratings [ mask ] - predicted_matrix [ mask ])** 2)\n",
        "    return np. sqrt (mse )\n",
        "\n",
        "  def predict_rating (self , user_id , item_id ):\n",
        "    \"\"\"\n",
        "    Predict a single rating using user and item factor dot product .\n",
        "    \"\"\"\n",
        "    return np.dot ( self . user_factors [ user_id ], self . item_factors [item_id ])\n",
        "\n",
        "  def recommend_items (self , user_id , n_recommendations =5):\n",
        "    \"\"\"\n",
        "      Recommend top N items for a given user ,\n",
        "    ignoring items already rated by that user .\n",
        "    \"\"\"\n",
        "    user_vector = self . user_factors [ user_id ]\n",
        "    predictions = user_vector @ self . item_factors .T\n",
        "    already_rated = ~np. isnan ( self . ratings [ user_id ])\n",
        "    predictions [ already_rated ] = -np.inf # to exclude rated items\n",
        "    top_items = np. argsort ( predictions ) [:: -1][: n_recommendations]\n",
        "    return top_items"
      ],
      "metadata": {
        "id": "ElUBcr0VA7oX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute both metrics, given a trained model and a test ratings matrix\n",
        "\n",
        "def evaluate_model (model , test_ratings ):\n",
        "  \"\"\"\n",
        "  Compute RMSE and MAE on a test set with known (non -NaN) ratings .\n",
        "  \"\"\"\n",
        "  predicted = model . user_factors @ model . item_factors .T\n",
        "  mask = ~np. isnan ( test_ratings )\n",
        "\n",
        "  errors = test_ratings [ mask ] - predicted [ mask ]\n",
        "  rmse = np. sqrt (np. mean ( errors **2) )\n",
        "  mae = np. mean (np.abs( errors ))\n",
        "\n",
        "  return rmse , mae"
      ],
      "metadata": {
        "id": "W6lkNCQpEAIm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent (SGD) version that updates biases and factor vectors together\n",
        "\n",
        "class BiasedSVD :\n",
        "  def __init__ (self , n_factors =20 , reg =0.1 , lr =0.005) :\n",
        "    self . n_factors = n_factors\n",
        "    self .reg = reg\n",
        "    self .lr = lr\n",
        "\n",
        "  def fit(self , ratings_matrix , n_epochs =10) :\n",
        "    self . ratings = ratings_matrix\n",
        "    self . n_users , self . n_items = ratings_matrix . shape\n",
        "\n",
        "    self . global_mean = np. nanmean ( self . ratings )\n",
        "    self . user_bias = np. zeros ( self . n_users )\n",
        "    self . item_bias = np. zeros ( self . n_items )\n",
        "    self . user_factors = np. random . normal (0, 0.1 , ( self . n_users , self . n_factors ))\n",
        "    self . item_factors = np. random . normal (0, 0.1 , ( self . n_items , self . n_factors ))\n",
        "\n",
        "    for epoch in range ( n_epochs ):\n",
        "      user_ids , item_ids = np. where (~ np. isnan ( self . ratings ))\n",
        "      indices = np. random . permutation (len( user_ids ))\n",
        "\n",
        "    for idx in indices :\n",
        "      u = user_ids [idx]\n",
        "\n",
        "      i = item_ids [idx]\n",
        "      rating = self . ratings [u, i]\n",
        "\n",
        "      # Current prediction\n",
        "      pred = ( self . global_mean +\n",
        "      self . user_bias [u] +\n",
        "      self . item_bias [i] +\n",
        "      np. dot ( self . user_factors [u], self .item_factors [i]))\n",
        "\n",
        "      # Error\n",
        "      e_ui = rating - pred\n",
        "\n",
        "      # Update bias terms\n",
        "      self . user_bias [u] += self .lr * ( e_ui - self .reg * self . user_bias [u])\n",
        "      self . item_bias [i] += self .lr * ( e_ui - self .reg * self . item_bias [i])\n",
        "\n",
        "      # Update latent factors\n",
        "      u_factors_old = self . user_factors [u]. copy ()\n",
        "      self . user_factors [u] += self .lr * (e_ui * self . item_factors [i] - self .reg * self .user_factors [u])\n",
        "      self . item_factors [i] += self .lr * ( e_ui * u_factors_old - self .reg * self .item_factors [i] )\n",
        "\n",
        "      # Monitor training progress ( RMSE )\n",
        "      rmse_val = self . _compute_rmse ()\n",
        "      print (f\" Epoch { epoch +1}/{ n_epochs }, RMSE = { rmse_val :.4f}\")\n",
        "\n",
        "  def _compute_rmse ( self ):\n",
        "    predictions = self . _full_prediction_matrix ()\n",
        "    mask = ~np. isnan ( self . ratings )\n",
        "    mse = np. mean (( self . ratings [ mask ] - predictions [ mask ]) ** 2)\n",
        "    return np. sqrt (mse )\n",
        "\n",
        "  def _full_prediction_matrix ( self ):\n",
        "    bias_term = ( self . global_mean +\n",
        "    self . user_bias [:, None ] +\n",
        "    self . item_bias [None , :])\n",
        "    factor_term = self . user_factors @ self . item_factors .T\n",
        "    return bias_term + factor_term\n",
        "\n",
        "  def predict (self , user_id , item_id ):\n",
        "   return self . _full_prediction_matrix ()[ user_id , item_id ]\n",
        "\n",
        "  def recommend_items (self , user_id , n_recommendations =5):\n",
        "    preds = self . _full_prediction_matrix ()[ user_id ]\n",
        "    rated_mask = ~np. isnan ( self . ratings [ user_id ])\n",
        "    preds [ rated_mask ] = -np.inf\n",
        "    return np. argsort ( preds ) [:: -1][: n_recommendations ]"
      ],
      "metadata": {
        "id": "8ZyQwi-LEGr1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \" __main__ \":\n",
        "  # Choose our SVD model\n",
        "  model = BiasedSVD ( n_factors =20 , reg =0.1 , lr =0.005)\n",
        "  # Fit on training set\n",
        "  model .fit( train_ratings , n_epochs =10)\n",
        "  # Evaluate on test set\n",
        "  rmse , mae = evaluate_model (model , test_ratings )\n",
        "  print (f\" Final RMSE on test = { rmse :.4f}, MAE = { mae :.4f}\")\n",
        "\n",
        "  # Make top -5 recommendations for user 0\n",
        "  user_id = 0\n",
        "  recommendations = model . recommend_items ( user_id , n_recommendations =5)\n",
        "  print (\"Top 5 Recommendations for user 0:\", recommendations )"
      ],
      "metadata": {
        "id": "LgfCvt7mFu3i"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â€¢ Backpropagation applies the chain rule to compute how changes in parameters influence the final loss.\n",
        "\n",
        "â€¢ The loss function measures the discrepancy between predictions and true labels.\n",
        "\n",
        "â€¢ The chain rule in calculus is the mathematical linchpin enabling efficient gradient computation.\n",
        "\n",
        "â€¢ Gradient descent moves parameters in the opposite direction of the gradient to minimize ð¿(ðœƒ).\n",
        "\n",
        "â€¢ Choices like activation function, loss function, and learning rate can vastly impact training efficacy and speed."
      ],
      "metadata": {
        "id": "X-Ybe0jxGjxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python snippet demonstrating the forward and backward pass for a single-neuron model with a Sigmoid activation and MSE loss:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Example values\n",
        "x, w, b, y = 2.0, 0.5, 0.1, 1.0 # input, weight, bias, target\n",
        "\n",
        "# Forward pass\n",
        "z = w * x + b # linear combination\n",
        "a = 1 / (1 + np.exp(-z)) # sigmoid activation\n",
        "loss = (y - a)**2 # MSE loss\n",
        "print(\"Forward pass results:\")\n",
        "print(f\"z = {z}, a = {a}, loss = {loss}\")\n",
        "\n",
        "# Backward pass\n",
        "dL_da = 2 * (a - y) # derivative of MSE w.r.t. a\n",
        "da_dz = a * (1 - a) # derivative of sigmoid w.r.t. z\n",
        "dz_dw = x # derivative of z w.r.t. w\n",
        "dz_db = 1 # derivative of z w.r.t. b\n",
        "\n",
        "# Combine derivatives to get the gradient\n",
        "dL_dw = dL_da * da_dz * dz_dw\n",
        "dL_db = dL_da * da_dz * dz_db\n",
        "print(\"\\nBackward pass (gradients):\")\n",
        "print(f\"dL/da = {dL_da}\")\n",
        "print(f\"da/dz = {da_dz}\")\n",
        "print(f\"dz/dw = {dz_dw}\")\n",
        "print(f\"dz/db = {dz_db}\")\n",
        "print(f\"dL/dw = {dL_dw}\")\n",
        "print(f\"dL/db = {dL_db}\")\n",
        "\n",
        "# Update parameters\n",
        "eta = 0.1\n",
        "w_new = w - eta * dL_dw\n",
        "b_new = b - eta * dL_db\n",
        "print(\"\\nUpdated parameters:\")\n",
        "print(f\"w_new = {w_new}\")\n",
        "print(f\"b_new = {b_new}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs90vypWGP7Z",
        "outputId": "45ac23f4-1773-46f1-af27-768afd23b07b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward pass results:\n",
            "z = 1.1, a = 0.7502601055951177, loss = 0.062370014857361766\n",
            "\n",
            "Backward pass (gradients):\n",
            "dL/da = -0.4994797888097646\n",
            "da/dz = 0.18736987954752055\n",
            "dz/dw = 2.0\n",
            "dz/db = 1\n",
            "dL/dw = -0.1871749357314132\n",
            "dL/db = -0.0935874678657066\n",
            "\n",
            "Updated parameters:\n",
            "w_new = 0.5187174935731413\n",
            "b_new = 0.10935874678657066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "\n",
        "â€¢ Michael A. Nielsen: Neural Networks and Deep Learning (free online resource).\n",
        "\n",
        "â€¢ Ian Goodfellow, Yoshua Bengio, Aaron Courville: Deep Learning (MIT Press).\n",
        "\n",
        "â€¢ Andrew Ngâ€™s Coursera course on Machine Learning for foundational gradient-based method insights."
      ],
      "metadata": {
        "id": "7vQtf25MGydq"
      }
    }
  ]
}